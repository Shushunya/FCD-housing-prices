{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d057453",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'fcd-house (3.11.9) (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/gonca/Desktop/asdf/FCD-housing-prices/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "from src.config import (\n",
    "    MASTER_DF_FILE,\n",
    "    RANDOM_SEED,\n",
    "    MODELS_DIR,\n",
    "    MUNICIPALITY_COLUMN,\n",
    "    WEATHER_COLUMNS,\n",
    "    SERVICES_COLUMNS,\n",
    "    AGE_COLUMNS,\n",
    "    INCOME_COLUMN,\n",
    "    POP_DENSITY_COLUMN,\n",
    "    URBAN_CLUSTER_FILE,\n",
    "    CLUSTER_LABELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv(URBAN_CLUSTER_FILE)\n",
    "target_column = \"log_price_sqm\"\n",
    "\n",
    "numerical_features = WEATHER_COLUMNS + SERVICES_COLUMNS + [INCOME_COLUMN, POP_DENSITY_COLUMN]\n",
    "categorical_features = AGE_COLUMNS + [\"cluster_urban\"]\n",
    "feature_cols = numerical_features + categorical_features\n",
    "\n",
    "cluster_counts = df_master['cluster_urban'].value_counts().sort_index()\n",
    "print(cluster_counts)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", \"passthrough\", categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b114765",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clusters = [0, 1, 4]\n",
    "for cluster_id in selected_clusters:\n",
    "    label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    print(f\"  Cluster {cluster_id}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"elasticnet\": {\"class\": ElasticNet, \"params\": {\"alpha\": 0.1, \"l1_ratio\": 0.5, \"random_state\": RANDOM_SEED, \"max_iter\": 5000}},\n",
    "    \"gbm\": {\"class\": GradientBoostingRegressor, \"params\": {\"n_estimators\": 100, \"max_depth\": 5, \"learning_rate\": 0.1, \"random_state\": RANDOM_SEED, \"subsample\": 0.8, \"max_features\": \"sqrt\"}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4dde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = {}\n",
    "cluster_pipelines = {}\n",
    "\n",
    "for cluster_id in selected_clusters:\n",
    "    cluster_label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    print(f\"\\nCluster {cluster_id}: {cluster_label}\")\n",
    "\n",
    "    df_cluster = df_master[df_master['cluster_urban'] == cluster_id].copy()\n",
    "    df_train = df_cluster[df_cluster['year'] < 2023].copy()\n",
    "    df_test = df_cluster[df_cluster['year'] == 2023].copy()\n",
    "    \n",
    "    if len(df_train) == 0 or len(df_test) == 0:\n",
    "        print(f\"WARNING: Insufficient data for cluster {cluster_id}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    X_train = df_train[feature_cols].copy()\n",
    "    y_train = df_train[target_column].copy()\n",
    "    groups_train = df_train[MUNICIPALITY_COLUMN].values\n",
    "\n",
    "    X_test = df_test[feature_cols].copy()\n",
    "    y_test = df_test[target_column].copy()\n",
    "\n",
    "    valid_train = X_train.notna().all(axis=1) & y_train.notna()\n",
    "    X_train = X_train[valid_train].reset_index(drop=True)\n",
    "    y_train = y_train[valid_train].reset_index(drop=True)\n",
    "    groups_train = groups_train[valid_train]\n",
    "    \n",
    "    valid_test = X_test.notna().all(axis=1) & y_test.notna()\n",
    "    X_test = X_test[valid_test].reset_index(drop=True)\n",
    "    y_test = y_test[valid_test].reset_index(drop=True)\n",
    "\n",
    "    cluster_results[cluster_id] = {}\n",
    "    cluster_pipelines[cluster_id] = {}\n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    scoring = {\"r2\": \"r2\", \"neg_mse\": \"neg_mean_squared_error\", \"neg_mae\": \"neg_mean_absolute_error\"}\n",
    "    \n",
    "    for model_key, config in model_configs.items():\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", config[\"class\"](**config[\"params\"])),\n",
    "        ])\n",
    "\n",
    "        cv_scores = cross_validate(\n",
    "            pipeline, X_train, y_train,\n",
    "            cv=gkf, groups=groups_train,\n",
    "            scoring=scoring, return_train_score=True, n_jobs=-1\n",
    "        )\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "        cluster_results[cluster_id][model_key] = {\n",
    "            'cv_r2_mean': cv_scores[\"test_r2\"].mean(),\n",
    "            'cv_r2_std': cv_scores[\"test_r2\"].std(),\n",
    "            'cv_rmse': np.sqrt(-cv_scores[\"test_neg_mse\"]).mean(),\n",
    "            'cv_mae': (-cv_scores[\"test_neg_mae\"]).mean(),\n",
    "            'test_r2': test_r2,\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_mae': test_mae\n",
    "        }\n",
    "        \n",
    "        cluster_pipelines[cluster_id][model_key] = pipeline\n",
    "\n",
    "print(\"\\nTraining complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = []\n",
    "\n",
    "for cluster_id in selected_clusters:\n",
    "    if cluster_id not in cluster_results:\n",
    "        continue\n",
    "    \n",
    "    cluster_label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    \n",
    "    for model_key in model_configs.keys():\n",
    "        if model_key not in cluster_results[cluster_id]:\n",
    "            continue\n",
    "        \n",
    "        metrics = cluster_results[cluster_id][model_key]\n",
    "        \n",
    "        results_summary.append({\n",
    "            \"Cluster ID\": cluster_id,\n",
    "            \"Cluster\": cluster_label,\n",
    "            \"Model\": model_key,\n",
    "            \"CV R² (2019-2022)\": metrics['cv_r2_mean'],\n",
    "            \"CV R² Std\": metrics['cv_r2_std'],\n",
    "            \"Test R² (2023)\": metrics['test_r2'],\n",
    "            \"CV RMSE\": metrics['cv_rmse'],\n",
    "            \"Test RMSE (2023)\": metrics['test_rmse'],\n",
    "            \"CV MAE\": metrics['cv_mae'],\n",
    "            \"Test MAE (2023)\": metrics['test_mae']\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "display(results_df.round(4))\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "results_path = MODELS_DIR / \"temporal_validation_by_cluster.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "test_r2_data = results_df.pivot(index='Cluster', columns='Model', values='Test R² (2023)')\n",
    "test_r2_data.plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'], alpha=0.7)\n",
    "axes[0].set_xlabel('Cluster', fontsize=12)\n",
    "axes[0].set_ylabel('Test R² (2023)', fontsize=12)\n",
    "axes[0].set_title('Test R² by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(title='Model', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "test_rmse_data = results_df.pivot(index='Cluster', columns='Model', values='Test RMSE (2023)')\n",
    "test_rmse_data.plot(kind='bar', ax=axes[1], color=['steelblue', 'coral'], alpha=0.7)\n",
    "axes[1].set_xlabel('Cluster', fontsize=12)\n",
    "axes[1].set_ylabel('Test RMSE (2023)', fontsize=12)\n",
    "axes[1].set_title('Test RMSE by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(title='Model', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b64668",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_data = []\n",
    "\n",
    "for cluster_id in selected_clusters:\n",
    "    if cluster_id not in cluster_pipelines:\n",
    "        continue\n",
    "    \n",
    "    cluster_label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    \n",
    "    for model_key, pipeline in cluster_pipelines[cluster_id].items():\n",
    "        regressor = pipeline.named_steps['regressor']\n",
    "        feature_names = numerical_features + categorical_features\n",
    "        \n",
    "        if model_key == 'elasticnet':\n",
    "            importances = np.abs(regressor.coef_)\n",
    "        elif model_key == 'gbm':\n",
    "            importances = regressor.feature_importances_\n",
    "        \n",
    "        for feat_name, importance in zip(feature_names, importances):\n",
    "            feature_importance_data.append({\n",
    "                'Cluster ID': cluster_id,\n",
    "                'Cluster': cluster_label,\n",
    "                'Model': model_key,\n",
    "                'Feature': feat_name,\n",
    "                'Importance': importance\n",
    "            })\n",
    "\n",
    "importance_df = pd.DataFrame(feature_importance_data)\n",
    "\n",
    "importance_path = MODELS_DIR / \"feature_importance_by_cluster.csv\"\n",
    "importance_df.to_csv(importance_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in selected_clusters:\n",
    "    if cluster_id not in cluster_pipelines:\n",
    "        continue\n",
    "    \n",
    "    cluster_label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    print(f\"\\n{cluster_label} - Top 10 Features:\")\n",
    "    \n",
    "    for model_key in model_configs.keys():\n",
    "        if model_key not in cluster_pipelines[cluster_id]:\n",
    "            continue\n",
    "        \n",
    "        cluster_model_df = importance_df[\n",
    "            (importance_df['Cluster ID'] == cluster_id) & \n",
    "            (importance_df['Model'] == model_key)\n",
    "        ].sort_values('Importance', ascending=False).head(10)\n",
    "        \n",
    "        print(f\"\\n{model_key.upper()}:\")\n",
    "        display(cluster_model_df[['Feature', 'Importance']].reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(selected_clusters), 2, figsize=(16, 5 * len(selected_clusters)))\n",
    "\n",
    "if len(selected_clusters) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, cluster_id in enumerate(selected_clusters):\n",
    "    if cluster_id not in cluster_pipelines:\n",
    "        continue\n",
    "    \n",
    "    cluster_label = CLUSTER_LABELS[\"cluster_urban\"].get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "\n",
    "    en_data = importance_df[\n",
    "        (importance_df['Cluster ID'] == cluster_id) & \n",
    "        (importance_df['Model'] == 'elasticnet')\n",
    "    ].sort_values('Importance', ascending=False).head(15)\n",
    "    \n",
    "    axes[idx, 0].barh(en_data['Feature'], en_data['Importance'], color='steelblue', alpha=0.7)\n",
    "    axes[idx, 0].set_xlabel('Absolute Coefficient', fontsize=11)\n",
    "    axes[idx, 0].set_title(f'{cluster_label} - ElasticNet', fontsize=12, fontweight='bold')\n",
    "    axes[idx, 0].invert_yaxis()\n",
    "    axes[idx, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    gbm_data = importance_df[\n",
    "        (importance_df['Cluster ID'] == cluster_id) & \n",
    "        (importance_df['Model'] == 'gbm')\n",
    "    ].sort_values('Importance', ascending=False).head(15)\n",
    "    \n",
    "    axes[idx, 1].barh(gbm_data['Feature'], gbm_data['Importance'], color='coral', alpha=0.7)\n",
    "    axes[idx, 1].set_xlabel('Feature Importance', fontsize=11)\n",
    "    axes[idx, 1].set_title(f'{cluster_label} - GradientBoostingRegressor', fontsize=12, fontweight='bold')\n",
    "    axes[idx, 1].invert_yaxis()\n",
    "    axes[idx, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86709ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_importance = importance_df.groupby(['Feature', 'Model', 'Cluster'])['Importance'].mean().reset_index()\n",
    "\n",
    "for model_key in model_configs.keys():\n",
    "    model_pivot = pivot_importance[pivot_importance['Model'] == model_key].pivot(\n",
    "        index='Feature', \n",
    "        columns='Cluster', \n",
    "        values='Importance'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    top_features = model_pivot.mean(axis=1).sort_values(ascending=False).head(20).index\n",
    "    model_pivot_top = model_pivot.loc[top_features]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(model_pivot_top, annot=True, fmt='.3f', cmap='YlOrRd', cbar_kws={'label': 'Importance'})\n",
    "    plt.title(f'Feature Importance Heatmap - {model_key.upper()}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Cluster', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcd-house (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
